# Introduction

<img src="gpu-architecture.png" alt="CUDA Architecture" width="400">

CUDA (Compute Unified Device Architecture) is a parallel computing platform and programming model developed by NVIDIA that enables developers to use GPUs for general-purpose computation. It provides direct access to the GPU’s massive parallel processing capabilities.

Triton is a programming language developed by OpenAI that simplifies writing high-performance GPU programs—similar to CUDA but with a focus on ease of use and optimization for modern AI workloads.

## Outline

1. **Fundamentals**  
   Learn the core principles behind GPU computing and the underlying architecture that makes CUDA and Triton so powerful.

2. **Writing Kernels**  
   Dive into the process of writing efficient GPU kernels using both CUDA and Triton, and understand the differences between low-level CUDA programming and Triton’s higher-level abstractions.

3. **Optimising**  
   Explore techniques to optimize your GPU code for performance, including parallelization strategies, memory management, and kernel fusion.

---

Happy Learning!
